# Advanced Database Systems

> [Course Website](https://15721.courses.cs.cmu.edu/spring2019/)

## Background

[CMU 15-445/645](https://15445.courses.cs.cmu.edu/fall2019/) or other intro course on databases.

## Lecture 1: Introduction

> [Lecture Video](https://www.bilibili.com/video/BV1aE411J7ak/?share_source=copy_web&vd_source=28bc1e9fa6c38d00b0fd9abfe3f23d5b)
> [Lecture Slides](https://15721.courses.cs.cmu.edu/spring2019/slides/01-inmemory.pdf)
> [Lecture Notes](https://15721.courses.cs.cmu.edu/spring2019/notes/01-inmemory.pdf)

### 1.1 Course Overview

- In-Memory DBMS Architecture
- Early Notable In-Memory DBMSs

### 1.2 Course Objectives

- Understand the design and implementation of modern in-memory database systems

### 1.3 Course Topics

- Concurrency Control
- Indexing
- Storage Models, Compression
- Parallel Join Algorithms
- Networking Protocols
- Logging && Recovery Methods
- Query Optimization, Execution, Compilation

### 1.4 Disk-Oriented DBMSs

Early DBMSs were designed for single-core CPU and disk-oriented storage. But now DRAM capacities are large enough that most databases can fit in memory.

- Structured data sets are smaller.
- Unstructured data(such as image) or semi-structured data(such as logfile) sets are larger.

> Why not just use a "tranditional" disk-oriented DBMS with a really large cache?

Disk-Oriented DBMS means that system is going to assume that anytime it needs to read data that in disk rather than memory. Such as Classical MySQL, It need move data from disk to buffer pool.

#### 1.4.1 Buffer Pool

When a query accesses a page, DBMS will first check if this page is in the buffer pool. If it is, then DBMS can read the data from the buffer pool. If it is not, then DBMS will read a frame from disk into the buffer pool. During this process, DBMS will evict a frame from the buffer pool if the buffer pool is full. And if the evicted frame is dirty, then DBMS will write it back to disk. During evicting frame, we need `latch` for `entry in Page Table` and `Evicted Page in Buffer Pool` to prevent others do the same thing that we are doing.

> [lock和latch是什么？](https://www.zhihu.com/question/309342903/answer/579255920)

![image-20230529012619482](https://raw.githubusercontent.com/Hxhao2000/ImagesBed/master/Images/image-20230529012619482.png)

Would the performance of the system be improved If we have a large enough Buffer Pool to prevent eviction happened ? Answer is **no**. Because all those steps we had to do are designed for disk-oriented architecture.

#### 1.4.2 Concurrency Control

In a disk-oriented DBMS, the systems assumes that a txn cound stall at any time when it tries to access data that is not in memory. However, other txns can still make progress, so we need `lock` for ACID guarantee. `Locks` are stored in a separate data structure to avoid being swapped to disk.

#### 1.4.3 Logging and Recovery

Most DBMSs use `Steal` + `No Force` buffer pool policies, so all modifications have to be flushed to the [WAL](https://en.wikipedia.org/wiki/Write-ahead_logging) before the txn commits. If the system crashes, then the DBMS can use the WAL to recover the database to a consistent state. Each log entry contains the old value and new value of the modified data item. Lots of work to keep track of [LSNs](https://en.wikipedia.org/wiki/Transaction_log) all throughout the DBMSs.

> [steal和force是什么？](https://blog.csdn.net/Singularinty/article/details/80747290)

#### 1.4.4 Disk-Oriented DBMS Overhead

![image-20230529012654365](https://raw.githubusercontent.com/Hxhao2000/ImagesBed/master/Images/image-20230529012654365.png)

### 1.5 In-Memory DBMSs

Assume that the primary storage location of the database is permanently in memory. Early ideas proposed in the 1980s, but feasible recently because DRAM prices are low and capacities are high.

#### 1.5.1 In-Memory DBMS Bottlenecks

- Locking and Latching
- Cache-line Misses
- Pointer chasing
- Predicate evaluations
- Data movement & copying
- Networking(between application & DBMS)

|                   |     L3 |  DRAM |        SSD |           HDD |
| ----------------- | -----: | ----: | ---------: | ------------: |
| **Read Latency**  | ~20 ns | 60 ns |  25,000 ns | 10,000,000 ns |
| **Write Latency** | ~20 ns | 60 ns | 300,000 ns | 10,000,000 ns |

#### 1.5.2 Data organization
An in-memory DBMS does not need to store the database in slotted pages but it will still organize tuples in blocks/pages:
- Direct memory pointers vs. record ids
- Fixed-length vs. variable-length data pools
- Use checksums to detect software errors from trashing the database.

![image-20230529012716502](https://raw.githubusercontent.com/Hxhao2000/ImagesBed/master/Images/image-20230529012716502.png)

#### 1.5.3 Why not MMAP?

`mmap` a database file into DRAM and let the OS manage swapping data in and out as needed. Use `madvice` and `msync` to give hints to the OS about what data is safe to flush.

Notable mmap DBMSs:
- [MongoDB](https://www.mongodb.com/)
- [MonetDB](https://www.monetdb.org/)
- [LMDB](https://symas.com/lmdb/)
- [MemSQL](https://www.singlestore.com/)

The Reasons why not use `mmap`:
- `OS` do not understand data that you try to do with database.
- Eviction and caching policies are not optimized for DBMS workloads.
- Cannot perform non-blocking memory access.
- The "on-disk" representation has to be the same as the "in-memory" representation.
- The DBMS has no way of knowing what pages are in memory or not.
- Various mmap-related syscalls are not partable.

#### 1.5.4 Concurrency Control

Observation: The cost of a txn acquiring a lock is the same as accessing data.

In-Memory DBMS may want to detect conflicts between txns at a different granulatiry.

- Fine-grained locking allows for better concurrency but requires more locks.
- Coarse-grained locking requires fewer locks but limits the amount of concurrency.

The DBMS can store locking information about each tuple together with its data.(just like version controll with optimistic lock?)

- This helps with CPU cache locality.
- Mutexes are too slow. Need to use CAS instructions.

New bottleneck is contention caused from txns trying access data at the same time.

#### 1.5.5 Indexing

Indexes are usually rebuilt in an in-memory DBMS after restart to avoid logging overhead.

#### 1.5.6 Query Processing

Sequential scans are no longer significantly faster than random access.

The traditional **tuple-at-a-time** iterator model is too slow because of function calls.

- This problem is more significant for OLAP DBMSs.

#### 1.5.7 Logging and Recovery

In-memory DBMSs still need a WAL on non-volatile storage since the system could halt at anytime.

- Use **group commit** to batch log entries and flush them together to amortize ==fsync== cost.
- May be possible to use more lightweight logging schemes(e.g., only store redo information because of there is no modification on disk util txn commit).

Also, due to no "dirty" pages, there is no need to maintain LSNs all thoughout the system.

The system also still takes checkpoints to speed up recovery time.

- Maintain a second copy of the database in memory that is updated by replaying the WAL.
- Switch to a special "copy-on-write" mode and then write a dump of the database to disk.
- Fork the DBMS process and then have the child process write its contents to disk.

## Project 1: Optimize a core component of a DBMS

## Project 2

## project 3
